{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/UKWh8cWU+97slJlSi/eG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rifkynursidik17/LSTM/blob/main/normalisasi_kata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57qtX95lWE8e"
      },
      "outputs": [],
      "source": [
        "kamus_baku_df = pd.read_excel('kamuskatabaku.xlsx').dropna()\n",
        "\n",
        "# Pastikan semua kolom bertipe string\n",
        "kamus_baku_df['tidak_baku'] = kamus_baku_df['tidak_baku'].astype(str).str.strip().str.lower()\n",
        "kamus_baku_df['kata_baku'] = kamus_baku_df['kata_baku'].astype(str).str.strip().str.lower()\n",
        "\n",
        "kamus_normalisasi = dict(zip(kamus_baku_df['tidak_baku'], kamus_baku_df['kata_baku']))\n",
        "\n",
        "# Pastikan file CSV punya kolom: 'slang', 'arti'\n",
        "kamus_slang_df = pd.read_excel('slangword.xlsx').dropna()\n",
        "\n",
        "kamus_slang_df['slang'] = kamus_slang_df['slang'].astype(str).str.strip().str.lower()\n",
        "kamus_slang_df['arti'] = kamus_slang_df['arti'].astype(str).str.strip().str.lower()\n",
        "\n",
        "kamus_slang = dict(zip(kamus_slang_df['slang'], kamus_slang_df['arti']))\n",
        "\n",
        "# Gabungkan kedua kamus (prioritas slang jika ada duplikasi)\n",
        "kamus_normalisasi.update(kamus_slang)\n",
        "\n",
        "print(f\"Total kata di kamus normalisasi: {len(kamus_normalisasi)}\")\n",
        "\n",
        "def hasil_normalisasi(text, kamus_normalisasi):\n",
        "    if not isinstance(text, str) or pd.isna(text):\n",
        "        return \"\", [], [], []\n",
        "\n",
        "    tokens = str(text).split()\n",
        "    hasil = []\n",
        "    kata_baku = []\n",
        "    kata_tidak_baku = []\n",
        "\n",
        "    for token in tokens:\n",
        "        token = str(token).strip().lower()\n",
        "        if token in kamus_normalisasi:\n",
        "            arti = kamus_normalisasi[token]\n",
        "            hasil.append(arti)\n",
        "            kata_tidak_baku.append(token)\n",
        "            kata_baku.append(arti)\n",
        "        else:\n",
        "            hasil.append(token)\n",
        "\n",
        "    hasil_normalisasi_text = \" \".join(hasil)\n",
        "    kata_tidak_baku_hash = hash(tuple(kata_tidak_baku))\n",
        "\n",
        "    return hasil_normalisasi_text, kata_baku, kata_tidak_baku, kata_tidak_baku_hash\n",
        "\n",
        "data['hasil_normalisasi'], data['kata_baku'], data['kata_tidak_baku'], data['kata_tidak_baku_hash'] = zip(\n",
        "    *data['case_folding'].apply(lambda x: hasil_normalisasi(x, kamus_normalisasi))\n",
        ")\n",
        "\n",
        "df = data[['ulasan', 'cleaning', 'case_folding', 'hasil_normalisasi']]\n",
        "df.head(5)\n"
      ]
    }
  ]
}